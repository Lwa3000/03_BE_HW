{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note to TA: I am going to submit again to finish this assignment.\n",
    "#             I am scraping the Indeed website instead of the ones in the homework because it's more useful for me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pymongo\n",
    "from pprint import pprint\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PyMongo to work with MongoDBs\n",
    "conn = 'mongodb://localhost:27017'\n",
    "client = pymongo.MongoClient(conn)\n",
    "\n",
    "# Define database and collection\n",
    "db = client.indeed_db\n",
    "collection = db.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "url = 'https://www.indeed.com/jobs?q=data+engineer&l=San+Francisco%2C+CA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve page with the requests module\n",
    "response = requests.get(url)\n",
    "# Create BeautifulSoup object; parse with 'lxml'\n",
    "soup = BeautifulSoup(response.text, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data Engineer', 'Senior Data Engineer', 'Data Engineer Consultant (Python & Hive / Presto)', 'Senior Data Engineer', 'Data Engineer', 'Data Engineer', 'Data Engineer', 'Data Engineer, SF', 'Data Engineer', 'Data Engineer', 'Data Engineer, Stream Platform', 'Data Engineer, Logging Platform', 'Data Engineer', 'Data Engineering Intern', 'Senior Data Engineer', 'React Engineer Hustler at Trustwork']\n"
     ]
    }
   ],
   "source": [
    "def extract_job_title_from_result(soup): \n",
    "    jobs=[]\n",
    "    results=soup.find_all(name=\"div\", attrs={\"class\":\"row\"})\n",
    "    for result in results:\n",
    "        for a in result.find_all(name=\"a\", attrs={\"data-tn-element\":\"jobTitle\"}):\n",
    "            jobs.append(a[\"title\"])\n",
    "    return jobs\n",
    "ls_titles=extract_job_title_from_result(soup)\n",
    "print(ls_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Yodlee', 'Trulia', 'Anectotal LLC', 'LeadGenius', 'Noodle.ai', 'Shipt', 'Segment', 'MLB.com', 'Twitter', 'Esha IT', 'Pinterest', 'Pinterest', 'hiQ LABS', 'Castlight Health', 'Blue Owl', 'Trustwork']\n"
     ]
    }
   ],
   "source": [
    "def extract_company_from_result(soup): \n",
    "    companies = []\n",
    "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
    "        company = div.find_all(name=\"span\", attrs={\"class\":\"company\"})\n",
    "        if len(company) > 0:\n",
    "            for b in company:\n",
    "                companies.append(b.text.strip())\n",
    "        else:\n",
    "            sec_try = div.find_all(name=\"span\", attrs={\"class\":\"result-link-source\"})\n",
    "            for span in sec_try:\n",
    "                companies.append(span.text.strip())\n",
    "    return companies\n",
    "\n",
    "ls_companies=extract_company_from_result(soup)\n",
    "print(ls_companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Redwood City, CA 94065', 'San Francisco, CA', 'Menlo Park, CA', 'Berkeley, CA 94704', 'San Francisco, CA', 'San Francisco, CA', 'San Francisco, CA 94103 (South Of Market area)', 'San Francisco, CA', 'San Francisco, CA 94103 (South Of Market area)', 'San Francisco, CA', 'San Francisco, CA 94103 (South Of Market area)', 'San Francisco, CA 94103 (South Of Market area)', 'San Francisco, CA 94105 (Financial District area)', 'San Francisco, CA 94105 (Financial District area)', 'San Francisco, CA', 'San Francisco, CA']\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "def extract_location_from_result(soup): \n",
    "    locations = []\n",
    "    spans = soup.findAll('span', attrs={'class': 'location'})\n",
    "    for span in spans:\n",
    "        locations.append(span.text)\n",
    "    return(locations)\n",
    "ls_locations=extract_location_from_result(soup)\n",
    "print(ls_locations)\n",
    "print(len(ls_locations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['An ability to analyze data and build data products. The Data Engineer is responsible for creating robust and accessible data sources for our customers in...', '5 Years of proven working experience as a data engineer. Technical expertise regarding data models, database design development, data mining and segmentation...', 'This data engineering role consultant opportunity involved building and maintaining data engineering pipelines, code, data quality checks, third-party...', 'Data sources that have defined schemas) and unstructured data (e.g. Experience with processing large volume of data and production data pipeline....', 'As a Data Engineer, you will collaborate with the Noodle Client Service team, Data Scientists, SW Engineers, and UX Designers, as well as industry-specific...', 'Shipt has a wide variety of data partners and as our data volumes. Data Engineering at Shipt primarily focuses on retailer catalog and general product data for...', 'Own and optimize Segment’s AWS internal data infrastructure to run the data warehouse and the data pipelines you build effectively and efficiently....', 'Data Engineer, Baseball Data. The Data Engineer position offers the opportunity to collaborate with other world-class engineers, product developers, and...', 'Our tools enable ML engineers to leverage Twitter data to improve their models. Streaming data processing solutions (e.g....', 'Data Engineer Position*. .- People who can articulate Data Quality, Data Cleansing, Data modeling, Data Visualization.- Able to articulate approach to handling...', 'We’re looking for a seasoned Big Data engineer to help us build and scale the next generation of near-realtime data processing and warehousing platform....', \"As a Data Engineer on the Logging Platform team you'll work on large Kafka deployment to enable the rest of the company to collect log messages and derive...\", 'Work closely with our data engineers to solve challenging technical problems. Data ETL experience. Enhance and maintain our data infrastructure....', 'Interest in data and data engineering. As an intern, you will have the unique opportunity to work with a team of experienced Data Engineers and Data Scientists...', \"You've built streaming data applications using open source tools. You are a solid software engineer Ideal, but not required:....\", 'Trustwork is looking for a highly-motivated Engineer Hustler to grow with our team. Extend Trustwork’s data pipeline through the collection, storage, processing...']\n"
     ]
    }
   ],
   "source": [
    "def extract_summary_from_result(soup): \n",
    "  summaries = []\n",
    "  spans = soup.findAll('span', attrs={'class': 'summary'})\n",
    "  for span in spans:\n",
    "    summaries.append(span.text.strip())\n",
    "  return(summaries)\n",
    "ls_summary=extract_summary_from_result(soup)\n",
    "print(ls_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "['https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0A38a9IVvk5r1TDo7iObPi9660u_wRAOWJAhHUAQ0rFsYKDo_PPgc_1F7ReqEpT1Kub3_SbEm0suqsYfbc7IVdPfNfgdCf3iQU5pacXmdWJ3rmvjj9eU4WcBrJuR6xZrmMQcxLWQ0ciE5HM0UcS8FaiQcJvJzYl8_3dqVnd9N2FS3msXcryUV_zTszRkmdzks1cjJIVY2MKYVx_FB6Ey5wibpHONs9jGnngZxNstrMgMy3sD4jmfzheoIE_O-GByJYS3eaY5Ym17zZKl_M2AhWWzA0MygTvLYtzAORctBbHz6jKw3zK0Bfed-ffUf9jBe9AzQdj0_331d9JMXRAzG5pVEn9ug2glGWBS8pQlzomwwAJxUdXZs9bPYzbgCQQG64cl-cLFBu1xCCMRlaJDVZ7SNO1iG9vuaUZafe_7DrHoLFTDDWG3EiZ3A38ISv4E8Ekx1VvKvWnlClSEruArgFOScJQG1KaGpMli0m66xM3gHCBT0wSBX9uJA92Xz3G7dnvkljtatl-aaMuKdCVq9W2SPEXtGsv1gvXPAJbRnkJDN5tOqC-MtGFn-MqxTONHu4KEGeLsqoDef7k5kZcR4UZ&vjs=3&p=1&sk=&fvj=0',\n",
      " 'https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0CZTNjLMuBQEc4UwMDLf68nYWD4vZp_o6pW13OpR78fsUbLF7akhdL4HTVuMU9ZbeK6p2rL4A4W-nNfc3zdHY1wmLw0SfOZ-Cv_RvbZspyyZlGpyyreBIbJ6BJR4f3pkSDKOoykvXxo0ZYCVfgfccVs4bCYqXV_SUifC95Z5f9JIKfr3yRT9Y7AKyDYnU-uK0XJOIm43U7-9Lr8mWMGocqNa8yWCVOu7Igr8RqzJK2i80TydF9Ifs3B2haAw8NkPRgsjDtOPtAKomuc2WZ8pKTMoUUw5r0Dp6DhwExDaGwRSuTVqSdX79vyvpSzgjVVkLXuwWCjTOW-_QGoPughMQJ2vEsrZMziB35lG5T-VbpGfJV6bm-R_3QvsdJHSigRJLptV62YR3-SIanHVK619m2DzmltyhkI5yMtieTHxBqNb8Yy5_wfac-f_rO39dYRNPHUnOhSoLZ0qNBYWdJ2JqWAZQCkdwZ6fAbSahUNfBu0Plt7Re0MbOW9XzEEeRqqiDFyoadUk0RqrTuNP6oSnfag&vjs=3&p=2&sk=&fvj=0',\n",
      " 'https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0B_IS6ir5FrYavPze7aoLnU7zcz7d-LAMBsb1QoM195dn7fH2JARgTdy4Cu4gAKlQ5whXFrLbeZodUInoULY5IaPbYLy4bk__Fo9nPwiQzhhQb4Ho7_Jixl7ITWorQv43XdYd_JZuO0HJuBLtc1E5EvKo7sqmT0ohxm4b4cFAv379VqLo4JBw7OBiSqXfxX0pYnBNGxVpKNq_R9S0OFphY_whIQsxoC549gGYXy8wPc5Jnq0p81jD_fjNdKdod1IlMTp1Ya78by2ITqfD87LBKBmUDMARzq8hUUC-OC9u7pwZC5vPiS34Uvf2bh4hxpcCWcDcJMSFkHgxyFBwgL76aFgFgXrLQqnrALNoQ0GVjcsXYVlKmwb726Mk32ahr9DIUoJ7PxyqXrpSrIVnBAwVgAu08JYmw5B6-ElKPUUrfMr9Nh1IGwQ9ah-8alk4vfTORtg9NG2ivMAJs2Ea6qIFliXKWhZ8bYS1rSMAosqoodOw==&vjs=3&p=3&sk=&fvj=1',\n",
      " 'https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0CwF5rjk5CA2ZsTDgD9KPpRbJhWYLPEfmyK9jLd9Vg37I3QNjUBvmFz7kziXk0DztlfdSxZ6JVdkIiaFiCTcxDpEkIPy4l9KpV8R3D-ApWxbz1R2jVOpg-sdee97CAE-cqVtiKmXnDysfmYzpNI7WsyHh3zGqvtzR4YWjKLltloI5daCuL-kGblrjmqEUr9XrwDf9MB6s0UV8E5XVkhJ-sQlS1XzhYISZC_aTyd_mETDU0l1qoqp5nxg6KWaDjKek3ZWha5afLxRUcaW3NgOd6STjcBbr9BTD0gcrCzD7dzJvze6Qty_Yuyu3-WlBfFUxfVwgxVk3BDsJefoHVLoAWRfCZRPEQq635jnMqIFxqqq3YgrvRmI1CRJU8PslRJLWbEcaotegCMDiqdctPsvaxyIOXrnvUnkY6Lc21nTu1Jrg8IonziC6obBJoHYdnLRFnBC1v9RZYlzQ==&vjs=3&p=4&sk=&fvj=1',\n",
      " 'https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0D3UvD5kBSgX9r9tFJCI4OL-41vvae__bcle4uMSq30h36AcPbHjl9bcVWQE4zSRT4mBKbnyz7JFMFYhUj0kXZ58e05-vsBd-e8fJnSv8flsCIkDG5v876yHPiw2CcNHi6mA3eLooZdKMYg1pQHezVEA1c8EB3SDBJTdq9xVE-OFYnCzXQThdl7DSRyOCw54QbD5K5PZjzs99nVaLOoDQaTA4lr94jsGUJITDOV-HoCs87Qv9WAD1BP4-ajz4RHFovM_PQ6BLQjMLyN9GEq9iQvcANHDLFMbwaCh-5VFD3wIu-4lyMx84NaxnbMv9nNDSurpFXGkSzvSNc4xDr5GwdilQ0klD_WaPUhuYHF8Uzv7FeulxfLJIkrBLEA86iH24e_JRVEmPi7y40ZEK6FgzY1G-aF7E6Byi7S1g7bCrZQNqRrifspAD_xG3qJ44sUvfuLRDRAqgZVnqqvGpKE-aVeaX5NQpvNro1-MOah-qZ0bzktywJjmNxa9y5FfDQ8PGI06XPZVPOBN3LI8ZtOmh49hJVM2vFGekQ=&vjs=3&p=5&sk=&fvj=0',\n",
      " 'https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0BrUkoy11B0xVs2L4uULRM6t4ce6LwAMdd2e8YwqDTf-OBLt97k1sinKUtkBlhN2LSEoLTiqwYUJrbvII2i8qfqzra7tq0ZRPcnsja4JSqdY3Uc_eDVt8H7OcTbqmpOLEOeax7iqqaRbhWzgAQvIlGf_Xzx-aUPXFK5CLsjNh69S0Kkj9W9_m3kVOvSKeX6n_j4XUC7A_ZdsYPs5O_XI3vzOiyjfFZ5Md4mPJc9rb48621ydsVIVqefb-B_eEHqMtntGvxzsR8umaq-gX12lNAQT419psa92utOsEah2ZOMkAna5VBLQmf5DNy6gay7AMK2VxRQPu9l2rW_vunSdRvLd39PJWeEgoRO2f9mxkjugh8f4H-8Y20LaB1lY4f7KsjA7I_eE8OVYvLHgH6RASkkdgtgdjOfsH7Xbv6iBWni82d7TYKKGRV4KwEz_FfozCaZv_Cxrb9G7PiEB3kk3yg2&vjs=3&p=6&sk=&fvj=1',\n",
      " 'https://www.indeed.com/rc/clk?jk=08d518766397fed1&fccid=7f8a3848ff617b22&vjs=3',\n",
      " 'https://www.indeed.com/rc/clk?jk=ec9dfa7da3a6e5ca&fccid=e07842a8df6e60cc&vjs=3',\n",
      " 'https://www.indeed.com/rc/clk?jk=a9b8abfbec4c7284&fccid=1ed502f6da51dc36&vjs=3',\n",
      " 'https://www.indeed.com/rc/clk?jk=938e900dc99f2504&fccid=bc1c9d9d782c6b91&vjs=3',\n",
      " 'https://www.indeed.com/rc/clk?jk=e4fd09b1afd8c5aa&fccid=7a3824693ee1074b&vjs=3',\n",
      " 'https://www.indeed.com/company/Esha-IT/jobs/Data-Engineer-e2835e3a99596a23?fccid=cd924e7ed28aee15&vjs=3',\n",
      " 'https://www.indeed.com/rc/clk?jk=271063358db6173a&fccid=43014b1412e0a7b6&vjs=3',\n",
      " 'https://www.indeed.com/rc/clk?jk=c6ea0e4bc901380b&fccid=43014b1412e0a7b6&vjs=3',\n",
      " 'https://www.indeed.com/rc/clk?jk=e44713823cb4d1df&fccid=bf6fb2c6c76aae45&vjs=3',\n",
      " 'https://www.indeed.com/rc/clk?jk=58326435846d9917&fccid=aafdb4fe9e36b658&vjs=3']\n"
     ]
    }
   ],
   "source": [
    "def extract_link_from_result(soup): \n",
    "    links=[]\n",
    "    results=soup.find_all(name=\"div\", attrs={\"class\":\"row\"})\n",
    "    for result in results:\n",
    "        for a in result.find_all(name=\"a\", attrs={\"class\":\"jobtitle\"},href=True):\n",
    "            links.append(\"https://www.indeed.com\"+a[\"href\"])\n",
    "\n",
    "    results=soup.find_all(name=\"h2\", attrs={\"class\":\"jobtitle\"})\n",
    "    for result in results:\n",
    "        for a in result.find_all(name=\"a\",href=True):\n",
    "            links.append(\"https://www.indeed.com\"+a[\"href\"])\n",
    "    return links\n",
    "\n",
    "ls_links=extract_link_from_result(soup)\n",
    "print(len(ls_links))\n",
    "pprint(ls_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_link_from_result(soup): \n",
    "#     links=[]\n",
    "#     results=soup.find_all(name=\"h2\", attrs={\"class\":\"jobtitle\"})\n",
    "#     for result in results:\n",
    "#         for a in result.find_all(name=\"a\",href=True):\n",
    "#             links.append(a[\"href\"])\n",
    "#     return links\n",
    "# ls_links=extract_link_from_result(soup)\n",
    "# print(len(ls_links))\n",
    "# pprint(ls_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:find the total number of jobs and use splinter to navigate to the next page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Scrape datetime': datetime.datetime(2018, 4, 23, 19, 55, 39, 442972),\n",
      "  'company': 'Yodlee',\n",
      "  'link': 'https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0A38a9IVvk5r1TDo7iObPi9660u_wRAOWJAhHUAQ0rFsYKDo_PPgc_1F7ReqEpT1Kub3_SbEm0suqsYfbc7IVdPfNfgdCf3iQU5pacXmdWJ3rmvjj9eU4WcBrJuR6xZrmMQcxLWQ0ciE5HM0UcS8FaiQcJvJzYl8_3dqVnd9N2FS3msXcryUV_zTszRkmdzks1cjJIVY2MKYVx_FB6Ey5wibpHONs9jGnngZxNstrMgMy3sD4jmfzheoIE_O-GByJYS3eaY5Ym17zZKl_M2AhWWzA0MygTvLYtzAORctBbHz6jKw3zK0Bfed-ffUf9jBe9AzQdj0_331d9JMXRAzG5pVEn9ug2glGWBS8pQlzomwwAJxUdXZs9bPYzbgCQQG64cl-cLFBu1xCCMRlaJDVZ7SNO1iG9vuaUZafe_7DrHoLFTDDWG3EiZ3A38ISv4E8Ekx1VvKvWnlClSEruArgFOScJQG1KaGpMli0m66xM3gHCBT0wSBX9uJA92Xz3G7dnvkljtatl-aaMuKdCVq9W2SPEXtGsv1gvXPAJbRnkJDN5tOqC-MtGFn-MqxTONHu4KEGeLsqoDef7k5kZcR4UZ&vjs=3&p=1&sk=&fvj=0',\n",
      "  'location': 'Redwood City, CA 94065',\n",
      "  'summary': 'An ability to analyze data and build data products. The Data '\n",
      "             'Engineer is responsible for creating robust and accessible data '\n",
      "             'sources for our customers in...',\n",
      "  'title': 'Data Engineer'},\n",
      " {'Scrape datetime': datetime.datetime(2018, 4, 23, 19, 55, 39, 442978),\n",
      "  'company': 'Trulia',\n",
      "  'link': 'https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0CZTNjLMuBQEc4UwMDLf68nYWD4vZp_o6pW13OpR78fsUbLF7akhdL4HTVuMU9ZbeK6p2rL4A4W-nNfc3zdHY1wmLw0SfOZ-Cv_RvbZspyyZlGpyyreBIbJ6BJR4f3pkSDKOoykvXxo0ZYCVfgfccVs4bCYqXV_SUifC95Z5f9JIKfr3yRT9Y7AKyDYnU-uK0XJOIm43U7-9Lr8mWMGocqNa8yWCVOu7Igr8RqzJK2i80TydF9Ifs3B2haAw8NkPRgsjDtOPtAKomuc2WZ8pKTMoUUw5r0Dp6DhwExDaGwRSuTVqSdX79vyvpSzgjVVkLXuwWCjTOW-_QGoPughMQJ2vEsrZMziB35lG5T-VbpGfJV6bm-R_3QvsdJHSigRJLptV62YR3-SIanHVK619m2DzmltyhkI5yMtieTHxBqNb8Yy5_wfac-f_rO39dYRNPHUnOhSoLZ0qNBYWdJ2JqWAZQCkdwZ6fAbSahUNfBu0Plt7Re0MbOW9XzEEeRqqiDFyoadUk0RqrTuNP6oSnfag&vjs=3&p=2&sk=&fvj=0',\n",
      "  'location': 'San Francisco, CA',\n",
      "  'summary': '5 Years of proven working experience as a data engineer. '\n",
      "             'Technical expertise regarding data models, database design '\n",
      "             'development, data mining and segmentation...',\n",
      "  'title': 'Senior Data Engineer'},\n",
      " {'Scrape datetime': datetime.datetime(2018, 4, 23, 19, 55, 39, 442979),\n",
      "  'company': 'Anectotal LLC',\n",
      "  'link': 'https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0B_IS6ir5FrYavPze7aoLnU7zcz7d-LAMBsb1QoM195dn7fH2JARgTdy4Cu4gAKlQ5whXFrLbeZodUInoULY5IaPbYLy4bk__Fo9nPwiQzhhQb4Ho7_Jixl7ITWorQv43XdYd_JZuO0HJuBLtc1E5EvKo7sqmT0ohxm4b4cFAv379VqLo4JBw7OBiSqXfxX0pYnBNGxVpKNq_R9S0OFphY_whIQsxoC549gGYXy8wPc5Jnq0p81jD_fjNdKdod1IlMTp1Ya78by2ITqfD87LBKBmUDMARzq8hUUC-OC9u7pwZC5vPiS34Uvf2bh4hxpcCWcDcJMSFkHgxyFBwgL76aFgFgXrLQqnrALNoQ0GVjcsXYVlKmwb726Mk32ahr9DIUoJ7PxyqXrpSrIVnBAwVgAu08JYmw5B6-ElKPUUrfMr9Nh1IGwQ9ah-8alk4vfTORtg9NG2ivMAJs2Ea6qIFliXKWhZ8bYS1rSMAosqoodOw==&vjs=3&p=3&sk=&fvj=1',\n",
      "  'location': 'Menlo Park, CA',\n",
      "  'summary': 'This data engineering role consultant opportunity involved '\n",
      "             'building and maintaining data engineering pipelines, code, data '\n",
      "             'quality checks, third-party...',\n",
      "  'title': 'Data Engineer Consultant (Python & Hive / Presto)'},\n",
      " {'Scrape datetime': datetime.datetime(2018, 4, 23, 19, 55, 39, 442981),\n",
      "  'company': 'LeadGenius',\n",
      "  'link': 'https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0CwF5rjk5CA2ZsTDgD9KPpRbJhWYLPEfmyK9jLd9Vg37I3QNjUBvmFz7kziXk0DztlfdSxZ6JVdkIiaFiCTcxDpEkIPy4l9KpV8R3D-ApWxbz1R2jVOpg-sdee97CAE-cqVtiKmXnDysfmYzpNI7WsyHh3zGqvtzR4YWjKLltloI5daCuL-kGblrjmqEUr9XrwDf9MB6s0UV8E5XVkhJ-sQlS1XzhYISZC_aTyd_mETDU0l1qoqp5nxg6KWaDjKek3ZWha5afLxRUcaW3NgOd6STjcBbr9BTD0gcrCzD7dzJvze6Qty_Yuyu3-WlBfFUxfVwgxVk3BDsJefoHVLoAWRfCZRPEQq635jnMqIFxqqq3YgrvRmI1CRJU8PslRJLWbEcaotegCMDiqdctPsvaxyIOXrnvUnkY6Lc21nTu1Jrg8IonziC6obBJoHYdnLRFnBC1v9RZYlzQ==&vjs=3&p=4&sk=&fvj=1',\n",
      "  'location': 'Berkeley, CA 94704',\n",
      "  'summary': 'Data sources that have defined schemas) and unstructured data '\n",
      "             '(e.g. Experience with processing large volume of data and '\n",
      "             'production data pipeline....',\n",
      "  'title': 'Senior Data Engineer'},\n",
      " {'Scrape datetime': datetime.datetime(2018, 4, 23, 19, 55, 39, 442982),\n",
      "  'company': 'Noodle.ai',\n",
      "  'link': 'https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0D3UvD5kBSgX9r9tFJCI4OL-41vvae__bcle4uMSq30h36AcPbHjl9bcVWQE4zSRT4mBKbnyz7JFMFYhUj0kXZ58e05-vsBd-e8fJnSv8flsCIkDG5v876yHPiw2CcNHi6mA3eLooZdKMYg1pQHezVEA1c8EB3SDBJTdq9xVE-OFYnCzXQThdl7DSRyOCw54QbD5K5PZjzs99nVaLOoDQaTA4lr94jsGUJITDOV-HoCs87Qv9WAD1BP4-ajz4RHFovM_PQ6BLQjMLyN9GEq9iQvcANHDLFMbwaCh-5VFD3wIu-4lyMx84NaxnbMv9nNDSurpFXGkSzvSNc4xDr5GwdilQ0klD_WaPUhuYHF8Uzv7FeulxfLJIkrBLEA86iH24e_JRVEmPi7y40ZEK6FgzY1G-aF7E6Byi7S1g7bCrZQNqRrifspAD_xG3qJ44sUvfuLRDRAqgZVnqqvGpKE-aVeaX5NQpvNro1-MOah-qZ0bzktywJjmNxa9y5FfDQ8PGI06XPZVPOBN3LI8ZtOmh49hJVM2vFGekQ=&vjs=3&p=5&sk=&fvj=0',\n",
      "  'location': 'San Francisco, CA',\n",
      "  'summary': 'As a Data Engineer, you will collaborate with the Noodle Client '\n",
      "             'Service team, Data Scientists, SW Engineers, and UX Designers, '\n",
      "             'as well as industry-specific...',\n",
      "  'title': 'Data Engineer'},\n",
      " {'Scrape datetime': datetime.datetime(2018, 4, 23, 19, 55, 39, 442984),\n",
      "  'company': 'Shipt',\n",
      "  'link': 'https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0BrUkoy11B0xVs2L4uULRM6t4ce6LwAMdd2e8YwqDTf-OBLt97k1sinKUtkBlhN2LSEoLTiqwYUJrbvII2i8qfqzra7tq0ZRPcnsja4JSqdY3Uc_eDVt8H7OcTbqmpOLEOeax7iqqaRbhWzgAQvIlGf_Xzx-aUPXFK5CLsjNh69S0Kkj9W9_m3kVOvSKeX6n_j4XUC7A_ZdsYPs5O_XI3vzOiyjfFZ5Md4mPJc9rb48621ydsVIVqefb-B_eEHqMtntGvxzsR8umaq-gX12lNAQT419psa92utOsEah2ZOMkAna5VBLQmf5DNy6gay7AMK2VxRQPu9l2rW_vunSdRvLd39PJWeEgoRO2f9mxkjugh8f4H-8Y20LaB1lY4f7KsjA7I_eE8OVYvLHgH6RASkkdgtgdjOfsH7Xbv6iBWni82d7TYKKGRV4KwEz_FfozCaZv_Cxrb9G7PiEB3kk3yg2&vjs=3&p=6&sk=&fvj=1',\n",
      "  'location': 'San Francisco, CA',\n",
      "  'summary': 'Shipt has a wide variety of data partners and as our data '\n",
      "             'volumes. Data Engineering at Shipt primarily focuses on retailer '\n",
      "             'catalog and general product data for...',\n",
      "  'title': 'Data Engineer'},\n",
      " {'Scrape datetime': datetime.datetime(2018, 4, 23, 19, 55, 39, 442985),\n",
      "  'company': 'Segment',\n",
      "  'link': 'https://www.indeed.com/rc/clk?jk=08d518766397fed1&fccid=7f8a3848ff617b22&vjs=3',\n",
      "  'location': 'San Francisco, CA 94103 (South Of Market area)',\n",
      "  'summary': 'Own and optimize Segment’s AWS internal data infrastructure to '\n",
      "             'run the data warehouse and the data pipelines you build '\n",
      "             'effectively and efficiently....',\n",
      "  'title': 'Data Engineer'},\n",
      " {'Scrape datetime': datetime.datetime(2018, 4, 23, 19, 55, 39, 442987),\n",
      "  'company': 'MLB.com',\n",
      "  'link': 'https://www.indeed.com/rc/clk?jk=ec9dfa7da3a6e5ca&fccid=e07842a8df6e60cc&vjs=3',\n",
      "  'location': 'San Francisco, CA',\n",
      "  'summary': 'Data Engineer, Baseball Data. The Data Engineer position offers '\n",
      "             'the opportunity to collaborate with other world-class engineers, '\n",
      "             'product developers, and...',\n",
      "  'title': 'Data Engineer, SF'},\n",
      " {'Scrape datetime': datetime.datetime(2018, 4, 23, 19, 55, 39, 442988),\n",
      "  'company': 'Twitter',\n",
      "  'link': 'https://www.indeed.com/rc/clk?jk=a9b8abfbec4c7284&fccid=1ed502f6da51dc36&vjs=3',\n",
      "  'location': 'San Francisco, CA 94103 (South Of Market area)',\n",
      "  'summary': 'Our tools enable ML engineers to leverage Twitter data to '\n",
      "             'improve their models. Streaming data processing solutions '\n",
      "             '(e.g....',\n",
      "  'title': 'Data Engineer'},\n",
      " {'Scrape datetime': datetime.datetime(2018, 4, 23, 19, 55, 39, 442990),\n",
      "  'company': 'Esha IT',\n",
      "  'link': 'https://www.indeed.com/rc/clk?jk=938e900dc99f2504&fccid=bc1c9d9d782c6b91&vjs=3',\n",
      "  'location': 'San Francisco, CA',\n",
      "  'summary': 'Data Engineer Position*. .- People who can articulate Data '\n",
      "             'Quality, Data Cleansing, Data modeling, Data Visualization.- '\n",
      "             'Able to articulate approach to handling...',\n",
      "  'title': 'Data Engineer'},\n",
      " {'Scrape datetime': datetime.datetime(2018, 4, 23, 19, 55, 39, 442991),\n",
      "  'company': 'Pinterest',\n",
      "  'link': 'https://www.indeed.com/rc/clk?jk=e4fd09b1afd8c5aa&fccid=7a3824693ee1074b&vjs=3',\n",
      "  'location': 'San Francisco, CA 94103 (South Of Market area)',\n",
      "  'summary': 'We’re looking for a seasoned Big Data engineer to help us build '\n",
      "             'and scale the next generation of near-realtime data processing '\n",
      "             'and warehousing platform....',\n",
      "  'title': 'Data Engineer, Stream Platform'},\n",
      " {'Scrape datetime': datetime.datetime(2018, 4, 23, 19, 55, 39, 442993),\n",
      "  'company': 'Pinterest',\n",
      "  'link': 'https://www.indeed.com/company/Esha-IT/jobs/Data-Engineer-e2835e3a99596a23?fccid=cd924e7ed28aee15&vjs=3',\n",
      "  'location': 'San Francisco, CA 94103 (South Of Market area)',\n",
      "  'summary': \"As a Data Engineer on the Logging Platform team you'll work on \"\n",
      "             'large Kafka deployment to enable the rest of the company to '\n",
      "             'collect log messages and derive...',\n",
      "  'title': 'Data Engineer, Logging Platform'},\n",
      " {'Scrape datetime': datetime.datetime(2018, 4, 23, 19, 55, 39, 442994),\n",
      "  'company': 'hiQ LABS',\n",
      "  'link': 'https://www.indeed.com/rc/clk?jk=271063358db6173a&fccid=43014b1412e0a7b6&vjs=3',\n",
      "  'location': 'San Francisco, CA 94105 (Financial District area)',\n",
      "  'summary': 'Work closely with our data engineers to solve challenging '\n",
      "             'technical problems. Data ETL experience. Enhance and maintain '\n",
      "             'our data infrastructure....',\n",
      "  'title': 'Data Engineer'},\n",
      " {'Scrape datetime': datetime.datetime(2018, 4, 23, 19, 55, 39, 442996),\n",
      "  'company': 'Castlight Health',\n",
      "  'link': 'https://www.indeed.com/rc/clk?jk=c6ea0e4bc901380b&fccid=43014b1412e0a7b6&vjs=3',\n",
      "  'location': 'San Francisco, CA 94105 (Financial District area)',\n",
      "  'summary': 'Interest in data and data engineering. As an intern, you will '\n",
      "             'have the unique opportunity to work with a team of experienced '\n",
      "             'Data Engineers and Data Scientists...',\n",
      "  'title': 'Data Engineering Intern'},\n",
      " {'Scrape datetime': datetime.datetime(2018, 4, 23, 19, 55, 39, 442997),\n",
      "  'company': 'Blue Owl',\n",
      "  'link': 'https://www.indeed.com/rc/clk?jk=e44713823cb4d1df&fccid=bf6fb2c6c76aae45&vjs=3',\n",
      "  'location': 'San Francisco, CA',\n",
      "  'summary': \"You've built streaming data applications using open source \"\n",
      "             'tools. You are a solid software engineer Ideal, but not '\n",
      "             'required:....',\n",
      "  'title': 'Senior Data Engineer'},\n",
      " {'Scrape datetime': datetime.datetime(2018, 4, 23, 19, 55, 39, 442998),\n",
      "  'company': 'Trustwork',\n",
      "  'link': 'https://www.indeed.com/rc/clk?jk=58326435846d9917&fccid=aafdb4fe9e36b658&vjs=3',\n",
      "  'location': 'San Francisco, CA',\n",
      "  'summary': 'Trustwork is looking for a highly-motivated Engineer Hustler to '\n",
      "             'grow with our team. Extend Trustwork’s data pipeline through the '\n",
      "             'collection, storage, processing...',\n",
      "  'title': 'React Engineer Hustler at Trustwork'}]\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary that has all the jobs and put the dictionary in a mongoDB\n",
    "positions=[]\n",
    "d={}\n",
    "idx=0\n",
    "while idx<len(ls_titles):\n",
    "    d[\"title\"]=ls_titles[idx]\n",
    "    d[\"company\"]=ls_companies[idx]\n",
    "    d[\"location\"]=ls_locations[idx]\n",
    "    d[\"summary\"]=ls_summary[idx]\n",
    "    d[\"link\"]=ls_links[idx]\n",
    "    d[\"Scrape datetime\"]=datetime.datetime.utcnow()\n",
    "    positions.append(d)\n",
    "    d={}\n",
    "    idx+=1\n",
    "pprint(positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x110d84dc8>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.items.insert_many(positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x11066cb40>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# db.items.insert_many([{\"title\": \"testTitle\",\"location\":\"testLocation\"},{\"title\": \"testTitle2\",\"location\":\"testLocation2\"}])\n",
    "# # db.test.insert_many([{'x': i} for i in range(2)])\n",
    "# db.items.delete_one(\n",
    "#     {'title': 'testTitle2'}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'1Data Engineer'\n",
      "'BioCentury Inc.'\n",
      "'2Senior Data Engineer'\n",
      "'Blue Owl'\n",
      "'3Security and Data Integrity Engineer'\n",
      "'KQED Inc.'\n",
      "'4Data Engineer Consultant (Python & Hive / Presto)'\n",
      "'Anectotal LLC'\n",
      "'5Data Engineer'\n",
      "'Noodle.ai'\n",
      "'6Data Engineer'\n",
      "'Segment'\n",
      "'7Data Engineer'\n",
      "'Shipt'\n",
      "'8Data Engineer, SF'\n",
      "'MLB.com'\n",
      "'9Data Engineer'\n",
      "'Twitter'\n",
      "'10Data Engineer, Stream Platform'\n",
      "'Pinterest'\n",
      "'11Data Engineer, Logging Platform'\n",
      "'Pinterest'\n",
      "'12Data Engineer'\n",
      "'Esha IT'\n",
      "'13Data Engineering Intern'\n",
      "'Castlight Health'\n",
      "'14Machine Learning Engineer, Notification Data'\n",
      "'Pinterest'\n",
      "'15Data Engineer'\n",
      "'Yodlee'\n",
      "'16Senior Data Engineer'\n",
      "'Trulia'\n",
      "'17Data Engineer'\n",
      "'Yodlee'\n",
      "'18Senior Data Engineer'\n",
      "'Trulia'\n",
      "'19Data Engineer Consultant (Python & Hive / Presto)'\n",
      "'Anectotal LLC'\n",
      "'20Senior Data Engineer'\n",
      "'LeadGenius'\n",
      "'21Data Engineer'\n",
      "'Noodle.ai'\n",
      "'22Data Engineer'\n",
      "'Shipt'\n",
      "'23Data Engineer'\n",
      "'Segment'\n",
      "'24Data Engineer, SF'\n",
      "'MLB.com'\n",
      "'25Data Engineer'\n",
      "'Twitter'\n",
      "'26Data Engineer'\n",
      "'Esha IT'\n",
      "'27Data Engineer, Stream Platform'\n",
      "'Pinterest'\n",
      "'28Data Engineer, Logging Platform'\n",
      "'Pinterest'\n",
      "'29Data Engineer'\n",
      "'hiQ LABS'\n",
      "'30Data Engineering Intern'\n",
      "'Castlight Health'\n",
      "'31Senior Data Engineer'\n",
      "'Blue Owl'\n",
      "'32React Engineer Hustler at Trustwork'\n",
      "'Trustwork'\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "# Verify results:\n",
    "results = db.items.find()\n",
    "count=0\n",
    "try:\n",
    "    for result in results:\n",
    "        count+=1\n",
    "        pprint(str(count)+result['title'])\n",
    "        pprint(result['company'])\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.DeleteResult at 0x1106b42d0>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [PythonData]",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
